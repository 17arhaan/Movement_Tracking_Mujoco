{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🤖 Humanoid Model Visualization Dashboard\n",
        "\n",
        "Interactive dashboard for visualizing and analyzing trained RL models with advanced controls and metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n",
            "/Users/arhaan17/Coding/Movement_Tracking_Mujoco/venv/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mipywidgets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwidgets\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import SAC, TD3, A2C\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import time\n",
        "import os\n",
        "import threading\n",
        "from collections import deque\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelVisualizationDashboard:\n",
        "    def __init__(self, model_dir=\"models\"):\n",
        "        self.model_dir = model_dir\n",
        "        self.current_model = None\n",
        "        self.env = None\n",
        "        self.is_running = False\n",
        "        self.episode_rewards = deque(maxlen=100)\n",
        "        self.episode_lengths = deque(maxlen=100)\n",
        "        self.step_rewards = deque(maxlen=1000)\n",
        "        self.joint_positions = {}\n",
        "        self.metrics_data = []\n",
        "        self.setup_ui()\n",
        "        \n",
        "    def get_available_models(self):\n",
        "        \"\"\"Get list of available trained models\"\"\"\n",
        "        models = []\n",
        "        for file in os.listdir(self.model_dir):\n",
        "            if file.endswith('.zip'):\n",
        "                models.append(file)\n",
        "        return sorted(models)\n",
        "    \n",
        "    def setup_ui(self):\n",
        "        \"\"\"Create the interactive UI components\"\"\"\n",
        "        # Model selection\n",
        "        self.model_dropdown = widgets.Dropdown(\n",
        "            options=self.get_available_models(),\n",
        "            description='Model:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "        \n",
        "        # Environment selection\n",
        "        self.env_dropdown = widgets.Dropdown(\n",
        "            options=['Humanoid-v4', 'Humanoid-v5'],\n",
        "            value='Humanoid-v4',\n",
        "            description='Environment:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "        \n",
        "        # Control buttons\n",
        "        self.load_button = widgets.Button(\n",
        "            description='🔄 Load Model',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        \n",
        "        self.start_button = widgets.Button(\n",
        "            description='▶️ Start Simulation',\n",
        "            button_style='success',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        \n",
        "        self.stop_button = widgets.Button(\n",
        "            description='⏹️ Stop Simulation',\n",
        "            button_style='danger',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        \n",
        "        self.record_button = widgets.Button(\n",
        "            description='🎥 Record Video',\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='150px')\n",
        "        )\n",
        "        \n",
        "        # Performance parameters\n",
        "        self.deterministic_checkbox = widgets.Checkbox(\n",
        "            value=True,\n",
        "            description='Deterministic Actions',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        self.max_steps_slider = widgets.IntSlider(\n",
        "            value=1000,\n",
        "            min=100,\n",
        "            max=5000,\n",
        "            step=100,\n",
        "            description='Max Steps:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='400px')\n",
        "        )\n",
        "        \n",
        "        self.speed_slider = widgets.FloatSlider(\n",
        "            value=1.0,\n",
        "            min=0.1,\n",
        "            max=3.0,\n",
        "            step=0.1,\n",
        "            description='Speed:',\n",
        "            style={'description_width': 'initial'},\n",
        "            layout=widgets.Layout(width='300px')\n",
        "        )\n",
        "        \n",
        "        # Status and info\n",
        "        self.status_output = widgets.Output(layout={'border': '1px solid black'})\n",
        "        self.metrics_output = widgets.Output(layout={'border': '1px solid blue'})\n",
        "        \n",
        "        # Bind events\n",
        "        self.load_button.on_click(self.load_model)\n",
        "        self.start_button.on_click(self.start_simulation)\n",
        "        self.stop_button.on_click(self.stop_simulation)\n",
        "        self.record_button.on_click(self.record_video)\n",
        "        \n",
        "    def display_ui(self):\n",
        "        \"\"\"Display the complete UI\"\"\"\n",
        "        # Header\n",
        "        display(HTML('<h1 style=\"color: #2E86AB; text-align: center;\">🤖 Humanoid Model Dashboard</h1>'))\n",
        "        \n",
        "        # Model selection row\n",
        "        model_row = widgets.HBox([\n",
        "            self.model_dropdown,\n",
        "            self.env_dropdown,\n",
        "            self.load_button\n",
        "        ])\n",
        "        \n",
        "        # Control row\n",
        "        control_row = widgets.HBox([\n",
        "            self.start_button,\n",
        "            self.stop_button,\n",
        "            self.record_button\n",
        "        ])\n",
        "        \n",
        "        # Parameters row\n",
        "        params_row = widgets.HBox([\n",
        "            self.deterministic_checkbox,\n",
        "            self.max_steps_slider,\n",
        "            self.speed_slider\n",
        "        ])\n",
        "        \n",
        "        # Main layout\n",
        "        display(widgets.VBox([\n",
        "            model_row,\n",
        "            control_row,\n",
        "            params_row,\n",
        "            widgets.HTML('<hr>'),\n",
        "            widgets.HBox([\n",
        "                widgets.VBox([\n",
        "                    widgets.HTML('<h3>📊 Status & Metrics</h3>'),\n",
        "                    self.status_output\n",
        "                ]),\n",
        "                widgets.VBox([\n",
        "                    widgets.HTML('<h3>📈 Live Performance</h3>'),\n",
        "                    self.metrics_output\n",
        "                ])\n",
        "            ])\n",
        "        ]))\n",
        "    \n",
        "    def load_model(self, button):\n",
        "        \"\"\"Load the selected model\"\"\"\n",
        "        with self.status_output:\n",
        "            clear_output(wait=True)\n",
        "            print(f\"🔄 Loading model: {self.model_dropdown.value}\")\n",
        "            \n",
        "            try:\n",
        "                # Determine algorithm from filename\n",
        "                model_path = os.path.join(self.model_dir, self.model_dropdown.value)\n",
        "                \n",
        "                if 'SAC' in self.model_dropdown.value:\n",
        "                    self.current_model = SAC.load(model_path)\n",
        "                    algo = 'SAC'\n",
        "                elif 'TD3' in self.model_dropdown.value:\n",
        "                    self.current_model = TD3.load(model_path)\n",
        "                    algo = 'TD3'\n",
        "                elif 'A2C' in self.model_dropdown.value:\n",
        "                    self.current_model = A2C.load(model_path)\n",
        "                    algo = 'A2C'\n",
        "                else:\n",
        "                    print(\"❌ Unknown algorithm in filename\")\n",
        "                    return\n",
        "                \n",
        "                # Create environment\n",
        "                self.env = gym.make(self.env_dropdown.value, render_mode='human')\n",
        "                \n",
        "                print(f\"✅ Model loaded successfully!\")\n",
        "                print(f\"📋 Algorithm: {algo}\")\n",
        "                print(f\"🎮 Environment: {self.env_dropdown.value}\")\n",
        "                print(f\"📁 File: {self.model_dropdown.value}\")\n",
        "                \n",
        "                # Extract training steps from filename\n",
        "                steps = self.model_dropdown.value.split('_')[-1].replace('.zip', '')\n",
        "                print(f\"🎯 Training Steps: {steps}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error loading model: {str(e)}\")\n",
        "    \n",
        "    def start_simulation(self, button):\n",
        "        \"\"\"Start the simulation\"\"\"\n",
        "        if self.current_model is None:\n",
        "            with self.status_output:\n",
        "                print(\"⚠️ Please load a model first!\")\n",
        "            return\n",
        "        \n",
        "        self.is_running = True\n",
        "        thread = threading.Thread(target=self._run_simulation)\n",
        "        thread.start()\n",
        "    \n",
        "    def stop_simulation(self, button):\n",
        "        \"\"\"Stop the simulation\"\"\"\n",
        "        self.is_running = False\n",
        "        with self.status_output:\n",
        "            print(\"⏹️ Simulation stopped\")\n",
        "    \n",
        "    def _run_simulation(self):\n",
        "        \"\"\"Internal simulation loop\"\"\"\n",
        "        episode_count = 0\n",
        "        \n",
        "        while self.is_running:\n",
        "            episode_count += 1\n",
        "            obs, _ = self.env.reset()\n",
        "            done = False\n",
        "            truncated = False\n",
        "            episode_reward = 0\n",
        "            episode_length = 0\n",
        "            step_count = 0\n",
        "            \n",
        "            with self.status_output:\n",
        "                clear_output(wait=True)\n",
        "                print(f\"🎮 Running Episode {episode_count}\")\n",
        "                print(f\"⚙️ Speed: {self.speed_slider.value}x\")\n",
        "                print(f\"🎯 Max Steps: {self.max_steps_slider.value}\")\n",
        "                print(f\"🤖 Deterministic: {self.deterministic_checkbox.value}\")\n",
        "            \n",
        "            while not (done or truncated) and self.is_running and step_count < self.max_steps_slider.value:\n",
        "                action, _ = self.current_model.predict(\n",
        "                    obs, \n",
        "                    deterministic=self.deterministic_checkbox.value\n",
        "                )\n",
        "                obs, reward, done, truncated, info = self.env.step(action)\n",
        "                \n",
        "                episode_reward += reward\n",
        "                episode_length += 1\n",
        "                step_count += 1\n",
        "                \n",
        "                # Store step reward for real-time plotting\n",
        "                self.step_rewards.append(reward)\n",
        "                \n",
        "                # Update live metrics\n",
        "                if step_count % 50 == 0:  # Update every 50 steps\n",
        "                    self.update_live_metrics(episode_count, step_count, episode_reward, reward)\n",
        "                \n",
        "                # Control simulation speed\n",
        "                time.sleep(0.01 / self.speed_slider.value)\n",
        "            \n",
        "            # Store episode metrics\n",
        "            self.episode_rewards.append(episode_reward)\n",
        "            self.episode_lengths.append(episode_length)\n",
        "            \n",
        "            # Final episode update\n",
        "            self.update_episode_summary(episode_count, episode_reward, episode_length)\n",
        "            \n",
        "            if not self.is_running:\n",
        "                break\n",
        "    \n",
        "    def update_live_metrics(self, episode, step, episode_reward, step_reward):\n",
        "        \"\"\"Update live performance metrics\"\"\"\n",
        "        with self.metrics_output:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            # Create simple matplotlib plots for better compatibility\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "            fig.suptitle(f'Live Metrics - Episode {episode}, Step {step}')\n",
        "            \n",
        "            # Episode rewards plot\n",
        "            if len(self.episode_rewards) > 0:\n",
        "                axes[0,0].plot(list(self.episode_rewards), 'b-', marker='o')\n",
        "                axes[0,0].set_title('Episode Rewards')\n",
        "                axes[0,0].set_xlabel('Episode')\n",
        "                axes[0,0].set_ylabel('Total Reward')\n",
        "                axes[0,0].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Episode lengths plot\n",
        "            if len(self.episode_lengths) > 0:\n",
        "                axes[0,1].plot(list(self.episode_lengths), 'g-', marker='s')\n",
        "                axes[0,1].set_title('Episode Lengths')\n",
        "                axes[0,1].set_xlabel('Episode')\n",
        "                axes[0,1].set_ylabel('Steps')\n",
        "                axes[0,1].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Recent step rewards\n",
        "            if len(self.step_rewards) > 0:\n",
        "                recent_rewards = list(self.step_rewards)[-200:]  # Last 200 steps\n",
        "                axes[1,0].plot(recent_rewards, 'r-', alpha=0.7)\n",
        "                axes[1,0].set_title('Recent Step Rewards')\n",
        "                axes[1,0].set_xlabel('Recent Steps')\n",
        "                axes[1,0].set_ylabel('Step Reward')\n",
        "                axes[1,0].grid(True, alpha=0.3)\n",
        "            \n",
        "            # Current episode progress\n",
        "            progress = (step / self.max_steps_slider.value) * 100\n",
        "            axes[1,1].bar(['Progress'], [progress], color='skyblue')\n",
        "            axes[1,1].set_title('Episode Progress')\n",
        "            axes[1,1].set_ylabel('Percentage')\n",
        "            axes[1,1].set_ylim(0, 100)\n",
        "            axes[1,1].grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Display numeric metrics\n",
        "            print(f\"📊 Current Metrics:\")\n",
        "            print(f\"   Episode: {episode}\")\n",
        "            print(f\"   Step: {step}\")\n",
        "            print(f\"   Episode Reward: {episode_reward:.2f}\")\n",
        "            print(f\"   Last Step Reward: {step_reward:.4f}\")\n",
        "            if len(self.episode_rewards) > 0:\n",
        "                print(f\"   Avg Episode Reward: {np.mean(self.episode_rewards):.2f}\")\n",
        "                print(f\"   Best Episode Reward: {np.max(self.episode_rewards):.2f}\")\n",
        "    \n",
        "    def update_episode_summary(self, episode, reward, length):\n",
        "        \"\"\"Update episode summary\"\"\"\n",
        "        with self.status_output:\n",
        "            print(f\"\\n📋 Episode {episode} Complete:\")\n",
        "            print(f\"   Reward: {reward:.2f}\")\n",
        "            print(f\"   Length: {length} steps\")\n",
        "            print(f\"   Avg Reward: {reward/length:.4f} per step\")\n",
        "    \n",
        "    def record_video(self, button):\n",
        "        \"\"\"Record a video of the model performance\"\"\"\n",
        "        if self.current_model is None:\n",
        "            with self.status_output:\n",
        "                print(\"⚠️ Please load a model first!\")\n",
        "            return\n",
        "        \n",
        "        with self.status_output:\n",
        "            print(\"🎥 Recording video...\")\n",
        "        \n",
        "        # Create video environment\n",
        "        video_env = gym.make(self.env_dropdown.value, render_mode=\"rgb_array\")\n",
        "        video_env = RecordVideo(\n",
        "            video_env, \n",
        "            video_folder=\"videos\", \n",
        "            episode_trigger=lambda x: True,\n",
        "            name_prefix=f\"{self.model_dropdown.value.replace('.zip', '')}\"\n",
        "        )\n",
        "        \n",
        "        try:\n",
        "            obs, _ = video_env.reset()\n",
        "            done = False\n",
        "            truncated = False\n",
        "            step_count = 0\n",
        "            \n",
        "            while not (done or truncated) and step_count < 1000:\n",
        "                action, _ = self.current_model.predict(obs, deterministic=True)\n",
        "                obs, _, done, truncated, _ = video_env.step(action)\n",
        "                step_count += 1\n",
        "            \n",
        "            video_env.close()\n",
        "            \n",
        "            with self.status_output:\n",
        "                print(f\"✅ Video recorded successfully!\")\n",
        "                print(f\"📁 Check the 'videos' folder for the recording\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            with self.status_output:\n",
        "                print(f\"❌ Error recording video: {str(e)}\")\n",
        "    \n",
        "    def generate_performance_report(self):\n",
        "        \"\"\"Generate a comprehensive performance report\"\"\"\n",
        "        if len(self.episode_rewards) == 0:\n",
        "            print(\"⚠️ No data available. Run some episodes first!\")\n",
        "            return\n",
        "        \n",
        "        # Create comprehensive report\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle(f'Performance Report - {self.model_dropdown.value}', fontsize=16)\n",
        "        \n",
        "        # Episode rewards over time\n",
        "        axes[0,0].plot(self.episode_rewards, 'b-', alpha=0.7)\n",
        "        axes[0,0].set_title('Episode Rewards Over Time')\n",
        "        axes[0,0].set_xlabel('Episode')\n",
        "        axes[0,0].set_ylabel('Total Reward')\n",
        "        axes[0,0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Episode lengths\n",
        "        axes[0,1].plot(self.episode_lengths, 'g-', alpha=0.7)\n",
        "        axes[0,1].set_title('Episode Lengths Over Time')\n",
        "        axes[0,1].set_xlabel('Episode')\n",
        "        axes[0,1].set_ylabel('Episode Length')\n",
        "        axes[0,1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Reward distribution\n",
        "        axes[1,0].hist(self.episode_rewards, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        axes[1,0].set_title('Reward Distribution')\n",
        "        axes[1,0].set_xlabel('Episode Reward')\n",
        "        axes[1,0].set_ylabel('Frequency')\n",
        "        axes[1,0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Performance statistics\n",
        "        stats_text = f\"\"\"\n",
        "        Performance Statistics:\n",
        "        \n",
        "        Episodes: {len(self.episode_rewards)}\n",
        "        \n",
        "        Rewards:\n",
        "        • Mean: {np.mean(self.episode_rewards):.2f}\n",
        "        • Std: {np.std(self.episode_rewards):.2f}\n",
        "        • Min: {np.min(self.episode_rewards):.2f}\n",
        "        • Max: {np.max(self.episode_rewards):.2f}\n",
        "        \n",
        "        Episode Lengths:\n",
        "        • Mean: {np.mean(self.episode_lengths):.1f}\n",
        "        • Std: {np.std(self.episode_lengths):.1f}\n",
        "        • Min: {np.min(self.episode_lengths)}\n",
        "        • Max: {np.max(self.episode_lengths)}\n",
        "        \"\"\"\n",
        "        \n",
        "        axes[1,1].text(0.1, 0.5, stats_text, transform=axes[1,1].transAxes, \n",
        "                      fontsize=10, verticalalignment='center',\n",
        "                      bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
        "        axes[1,1].set_xlim(0, 1)\n",
        "        axes[1,1].set_ylim(0, 1)\n",
        "        axes[1,1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and display the dashboard\n",
        "dashboard = ModelVisualizationDashboard()\n",
        "dashboard.display_ui()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate performance report (run this after running some episodes)\n",
        "dashboard.generate_performance_report()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔧 Model Comparison Tool\n",
        "\n",
        "Compare performance between different models:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModelComparison:\n",
        "    def __init__(self, model_dir=\"models\"):\n",
        "        self.model_dir = model_dir\n",
        "        self.comparison_data = {}\n",
        "    \n",
        "    def evaluate_model(self, model_path, episodes=5):\n",
        "        \"\"\"Evaluate a model for multiple episodes\"\"\"\n",
        "        print(f\"🔄 Evaluating {model_path}...\")\n",
        "        \n",
        "        # Load model\n",
        "        if 'SAC' in model_path:\n",
        "            model = SAC.load(os.path.join(self.model_dir, model_path))\n",
        "        elif 'TD3' in model_path:\n",
        "            model = TD3.load(os.path.join(self.model_dir, model_path))\n",
        "        elif 'A2C' in model_path:\n",
        "            model = A2C.load(os.path.join(self.model_dir, model_path))\n",
        "        \n",
        "        env = gym.make(\"Humanoid-v4\", render_mode=None)\n",
        "        \n",
        "        rewards = []\n",
        "        lengths = []\n",
        "        \n",
        "        for episode in range(episodes):\n",
        "            obs, _ = env.reset()\n",
        "            done = False\n",
        "            truncated = False\n",
        "            episode_reward = 0\n",
        "            episode_length = 0\n",
        "            \n",
        "            while not (done or truncated) and episode_length < 1000:\n",
        "                action, _ = model.predict(obs, deterministic=True)\n",
        "                obs, reward, done, truncated, _ = env.step(action)\n",
        "                episode_reward += reward\n",
        "                episode_length += 1\n",
        "            \n",
        "            rewards.append(episode_reward)\n",
        "            lengths.append(episode_length)\n",
        "            print(f\"  Episode {episode+1}: Reward={episode_reward:.2f}, Length={episode_length}\")\n",
        "        \n",
        "        env.close()\n",
        "        \n",
        "        self.comparison_data[model_path] = {\n",
        "            'rewards': rewards,\n",
        "            'lengths': lengths,\n",
        "            'mean_reward': np.mean(rewards),\n",
        "            'std_reward': np.std(rewards),\n",
        "            'mean_length': np.mean(lengths),\n",
        "            'std_length': np.std(lengths)\n",
        "        }\n",
        "        \n",
        "        print(f\"✅ {model_path} - Mean Reward: {np.mean(rewards):.2f} ± {np.std(rewards):.2f}\")\n",
        "    \n",
        "    def compare_models(self, model_list, episodes=5):\n",
        "        \"\"\"Compare multiple models\"\"\"\n",
        "        for model in model_list:\n",
        "            self.evaluate_model(model, episodes)\n",
        "        \n",
        "        self.plot_comparison()\n",
        "    \n",
        "    def plot_comparison(self):\n",
        "        \"\"\"Plot comparison results\"\"\"\n",
        "        if not self.comparison_data:\n",
        "            print(\"No comparison data available\")\n",
        "            return\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Model Comparison Results', fontsize=16)\n",
        "        \n",
        "        models = list(self.comparison_data.keys())\n",
        "        mean_rewards = [self.comparison_data[m]['mean_reward'] for m in models]\n",
        "        std_rewards = [self.comparison_data[m]['std_reward'] for m in models]\n",
        "        mean_lengths = [self.comparison_data[m]['mean_length'] for m in models]\n",
        "        \n",
        "        # Mean rewards comparison\n",
        "        x_pos = range(len(models))\n",
        "        axes[0,0].bar(x_pos, mean_rewards, yerr=std_rewards, capsize=5, alpha=0.7)\n",
        "        axes[0,0].set_title('Mean Episode Rewards')\n",
        "        axes[0,0].set_ylabel('Reward')\n",
        "        axes[0,0].set_xticks(x_pos)\n",
        "        axes[0,0].set_xticklabels([m.split('_')[1] for m in models], rotation=45)\n",
        "        axes[0,0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Episode lengths comparison\n",
        "        axes[0,1].bar(x_pos, mean_lengths, alpha=0.7, color='green')\n",
        "        axes[0,1].set_title('Mean Episode Lengths')\n",
        "        axes[0,1].set_ylabel('Steps')\n",
        "        axes[0,1].set_xticks(x_pos)\n",
        "        axes[0,1].set_xticklabels([m.split('_')[1] for m in models], rotation=45)\n",
        "        axes[0,1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Reward distributions\n",
        "        for i, model in enumerate(models):\n",
        "            axes[1,0].hist(self.comparison_data[model]['rewards'], \n",
        "                          alpha=0.5, label=model.split('_')[1], bins=10)\n",
        "        axes[1,0].set_title('Reward Distributions')\n",
        "        axes[1,0].set_xlabel('Episode Reward')\n",
        "        axes[1,0].set_ylabel('Frequency')\n",
        "        axes[1,0].legend()\n",
        "        axes[1,0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Summary table\n",
        "        summary_text = \"Model Performance Summary:\\n\\n\"\n",
        "        for model in models:\n",
        "            data = self.comparison_data[model]\n",
        "            summary_text += f\"{model.split('_')[1]}:\\n\"\n",
        "            summary_text += f\"  Reward: {data['mean_reward']:.2f} ± {data['std_reward']:.2f}\\n\"\n",
        "            summary_text += f\"  Length: {data['mean_length']:.1f} ± {data['std_length']:.1f}\\n\\n\"\n",
        "        \n",
        "        axes[1,1].text(0.1, 0.5, summary_text, transform=axes[1,1].transAxes,\n",
        "                      fontsize=10, verticalalignment='center',\n",
        "                      bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
        "        axes[1,1].set_xlim(0, 1)\n",
        "        axes[1,1].set_ylim(0, 1)\n",
        "        axes[1,1].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Compare different models\n",
        "# Uncomment and modify the model names according to your available models\n",
        "\n",
        "# comparator = ModelComparison()\n",
        "# models_to_compare = [\n",
        "#     'SAC_100000.zip',\n",
        "#     'SAC_200000.zip',\n",
        "#     'TD3_100000.zip',\n",
        "#     'A2C_100000.zip'\n",
        "# ]\n",
        "# comparator.compare_models(models_to_compare, episodes=3)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Advanced Analysis Tools\n",
        "\n",
        "Additional analysis and visualization tools:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_training_progress():\n",
        "    \"\"\"Analyze training progress across different model checkpoints\"\"\"\n",
        "    model_dir = \"models\"\n",
        "    models = [f for f in os.listdir(model_dir) if f.endswith('.zip')]\n",
        "    \n",
        "    # Group by algorithm\n",
        "    algo_models = {'SAC': [], 'TD3': [], 'A2C': []}\n",
        "    \n",
        "    for model in models:\n",
        "        for algo in algo_models.keys():\n",
        "            if algo in model:\n",
        "                try:\n",
        "                    steps = int(model.split('_')[-1].replace('.zip', ''))\n",
        "                    algo_models[algo].append((steps, model))\n",
        "                except:\n",
        "                    pass\n",
        "    \n",
        "    # Sort by training steps\n",
        "    for algo in algo_models:\n",
        "        algo_models[algo].sort()\n",
        "    \n",
        "    # Display available models by algorithm\n",
        "    for algo, models in algo_models.items():\n",
        "        if models:\n",
        "            print(f\"\\n{algo} Models:\")\n",
        "            for steps, model_name in models[:10]:  # Show first 10\n",
        "                print(f\"  {steps:,} steps: {model_name}\")\n",
        "            if len(models) > 10:\n",
        "                print(f\"  ... and {len(models)-10} more\")\n",
        "\n",
        "analyze_training_progress()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎯 Usage Instructions\n",
        "\n",
        "### How to Use This Dashboard:\n",
        "\n",
        "1. **Load a Model**: \n",
        "   - Select a model from the dropdown\n",
        "   - Choose the environment version\n",
        "   - Click \"Load Model\"\n",
        "\n",
        "2. **Configure Parameters**:\n",
        "   - Set deterministic actions for consistent behavior\n",
        "   - Adjust max steps per episode\n",
        "   - Control simulation speed\n",
        "\n",
        "3. **Run Simulation**:\n",
        "   - Click \"Start Simulation\" to begin\n",
        "   - Watch live metrics update in real-time\n",
        "   - Use \"Stop Simulation\" to halt\n",
        "\n",
        "4. **Record Videos**:\n",
        "   - Click \"Record Video\" to save performance\n",
        "   - Videos are saved in the 'videos' folder\n",
        "\n",
        "5. **Analyze Performance**:\n",
        "   - Generate detailed performance reports\n",
        "   - Compare multiple models\n",
        "   - View training progress analysis\n",
        "\n",
        "### Features:\n",
        "- 📊 **Real-time Metrics**: Live performance tracking\n",
        "- 🎥 **Video Recording**: Save model demonstrations\n",
        "- 📈 **Advanced Plotting**: Interactive visualizations\n",
        "- 🔄 **Model Comparison**: Compare different algorithms\n",
        "- ⚙️ **Flexible Controls**: Adjust simulation parameters\n",
        "- 📋 **Detailed Reports**: Comprehensive performance analysis\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
